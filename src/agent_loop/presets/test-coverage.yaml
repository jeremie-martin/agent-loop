name: test-coverage
description: Add tests for untested critical paths with self-orchestrated verification

prompt_prefix: |
  FIRST: Find and read all markdown documentation in this project before doing anything else.
  Search for and read: README files (root and subdirectories), CLAUDE.md, AGENTS.md, and all
  files in docs/ or documentation/ directories. Understand the codebase's patterns, conventions,
  and architecture. Only then proceed with your task.

  IMPORTANT - When spawning sub-agents:
  Sub-agents do not automatically have the context you have. For each sub-agent you spawn:
  1. Give it the exact file paths to relevant documentation (CLAUDE.md, README, etc.)
  2. Explicitly instruct it to read those files completely before starting its task
  3. Include any other specific files it needs to examine

  Do not assume sub-agents will find documentation on their own — give them the paths.

prompt_suffix: |
  Do not use the "question" tool or any tool requiring user input.
  Stage and commit your changes at the end with a descriptive message.

  CRITICAL - When a test you write fails:
  1. First check: Is your test wrong? (wrong assertion, bad setup, misunderstood API)
     -> If yes, fix your test.
  2. If your test logic is correct, you may have found a bug in the implementation.
     -> Do NOT "fix" your test to match broken behavior.
     -> Do NOT delete the test.
     -> Mark it as skipped with a clear reason: @pytest.mark.skip(reason="Reveals bug: [description]")
     -> This preserves the test as documentation while not breaking CI.

  Never weaken or delete a correct test just because it fails. A failing test that catches
  a real bug is valuable—it just needs the implementation fixed, not the test.

modes:
  - name: coverage
    prompt: |
      A well-tested codebase has coverage where it matters: critical paths, complex
      logic, and places where bugs would hurt most. More tests are not better—
      better tests are better.

      Meaningful test coverage means:
      - User-facing features have tests that verify behavior
      - Data handling code has tests including edge cases
      - Complex logic has tests that would actually catch bugs

      Focus on gaps that matter. Write tests that would catch real bugs, not tests
      that just increase coverage numbers.

      After writing tests, run them. If a test fails, determine whether your test
      is wrong or you've found an implementation bug. Fix incorrect tests; mark
      bug-revealing tests as skipped with a clear reason.

      "No new tests needed" is a valid outcome if the critical paths are covered.

      **After completing your changes**, orchestrate verification:

      1. Spawn a sub-agent to review your work. Give it:
         - The paths to relevant documentation files and instruct it to read them first
         - The test files you created or modified
         - Instruction to check: do tests cover meaningful behavior? Would they
           catch real bugs? Are any redundant with existing tests?

      2. Spawn a filter sub-agent. Give it the verification feedback and ask:
         which concerns are genuine vs over-cautious?

      3. Address filtered feedback, then commit.

  - name: consolidation
    prompt: |
      A lean test suite runs faster and fails more clearly. Tests that overlap,
      check implementation details instead of behavior, or have excessive setup
      all make the suite harder to maintain.

      Signs of tests that need consolidation:
      - Multiple tests verifying the same behavior
      - Tests coupled to implementation details rather than outcomes
      - Excessive setup that obscures what's being tested

      Fewer, better tests. Deleting a redundant test is as valuable as adding
      a missing one.

      Run the suite after consolidation to confirm nothing broke.

      **After completing your changes**, orchestrate verification:

      Spawn a sub-agent to review your work. Give it:
      - The paths to relevant documentation files and instruct it to read them first
      - The test files you modified
      - Instruction to check: did consolidation preserve test coverage?
        Are any behaviors now untested? Any further consolidation possible?

      Address the feedback, then commit.
