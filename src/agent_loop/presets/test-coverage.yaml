name: test-coverage
description: Add tests for untested critical paths—quality over quantity

prompt_prefix: |
  Tests exist to catch bugs and document behavior. More tests are not better—
  better tests are better. A small suite that covers critical paths beats a
  large suite that tests trivia.

prompt_suffix: |
  Do not commit changes - they will be reviewed and committed at the end of the cycle.
  Do not use the "question" tool or any tool requiring user input.
  If you find no meaningful gaps, make no changes. "No new tests needed" is a valid outcome.

modes:
  - name: gaps
    prompt: |
      Identify what's untested, but be selective about what matters.

      Survey the codebase to understand:
      - What code paths handle user input, external data, or money?
      - What logic has complex branching or edge cases?
      - What has broken before (check git history for bug fixes)?

      Compare this against the existing test suite. What critical behaviors lack tests?

      Prioritize ruthlessly. Rank gaps by:
      1. Blast radius if broken (user-facing > internal, data loss > cosmetic)
      2. Complexity (tricky logic > straightforward CRUD)
      3. Change frequency (often-modified code > stable code)

      Pick the single highest-priority gap. Write tests for that one area only.
      One well-tested critical path per iteration, not broad shallow coverage.

      After writing tests, run them to confirm they pass.

  - name: edges
    prompt: |
      Edge cases reveal assumptions. Good tests probe boundaries.

      Review the existing test suite. For tested functionality, ask:
      - What happens at zero, one, many?
      - What happens with empty input, null, missing fields?
      - What happens at boundaries (max length, timeout, overflow)?

      Don't add edge cases everywhere—focus on code where edge cases matter:
      - Parsing and validation logic
      - Numeric calculations
      - State machines and transitions

      Pick one area with weak edge case coverage. Add the edge cases that would
      catch real bugs. Skip edge cases that test language semantics (Python already
      handles empty lists correctly).

      Run tests after adding them.

  - name: consolidation
    prompt: |
      A lean test suite runs faster and fails more clearly.

      Review the test suite for redundancy:
      - Tests that verify the same behavior in different words
      - Tests that would fail together (if one fails, the other always fails too)
      - Tests that check implementation details rather than behavior
      - Tests with excessive setup that obscures what's being tested

      Consolidate where possible:
      - Merge tests that check the same behavior
      - Delete tests that duplicate others
      - Simplify tests with clearer assertions

      The goal is fewer, better tests. Deleting a redundant test is as valuable
      as adding a missing one.

      Run the suite after consolidation to confirm nothing broke.

review:
  enabled: true
  scope_globs:
    - "**/test_*.py"
    - "**/*_test.py"
    - "**/tests/**/*.py"
    - "**/*.test.ts"
    - "**/*.spec.ts"
    - "**/test/**"
    - "**/__tests__/**"
  check_prompt: |
    Review only the test file changes. Ignore unrelated files.

    For each new or modified test, verify:
    1. The test actually runs and passes
    2. The test would fail if the behavior it tests were broken
    3. The test covers something not already covered elsewhere

    Run the test suite to confirm all tests pass.

  filter_prompt: |
    Filter out tests that don't earn their keep:
    - Tests that verify trivial behavior (getters, simple assignments)
    - Tests that duplicate existing coverage
    - Tests that are flaky or timing-dependent
    - Tests that check implementation details rather than behavior
    - Tests where the setup is more complex than the code being tested

    Be aggressive. A test that doesn't catch bugs is maintenance burden.
    Only keep tests that would catch real problems.
