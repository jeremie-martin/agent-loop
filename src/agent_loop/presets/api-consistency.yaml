name: api-consistency
description: Make API endpoints predictable with self-orchestrated verification

prompt_prefix: |
  FIRST: Find and read all markdown documentation in this project before doing anything else.
  Search for and read: README files (root and subdirectories), CLAUDE.md, AGENTS.md, and all
  files in docs/ or documentation/ directories. Understand the codebase's patterns, conventions,
  and architecture. Only then proceed with your task.

  When spawning sub-agents, explicitly instruct each one to first read all project
  documentation (README files, CLAUDE.md, AGENTS.md, docs/ and documentation/ directories)
  before starting its task.

prompt_suffix: |
  Do not use the "question" tool or any tool requiring user input.
  Stage and commit your changes at the end with a descriptive message.

modes:
  - name: contracts
    prompt: |
      Make APIs predictable. Once someone knows one endpoint, they should be able
      to guess how others work.

      Review API endpoint definitions for consistency:

      **Naming:**
      - Do resources use plural nouns? (`/users`, not `/user`)
      - Are HTTP verbs used correctly? (GET reads, POST creates, PUT/PATCH updates, DELETE removes)
      - Is nesting consistent? (`/users/{id}/posts` vs `/posts?user_id=...`)
      - Do similar operations have similar URL patterns?

      **Responses:**
      - Do success responses follow the same structure? (data wrapper, metadata location)
      - Are error responses uniform? (same fields, same HTTP status code meanings)
      - Is pagination handled consistently? (same query params, same response shape)
      - Are empty results handled the same way? (empty array vs null vs omitted)

      **Validation:**
      - Are required fields enforced consistently?
      - Do similar fields have similar validation? (email fields, dates, IDs)
      - Are validation errors structured the same way? (which field, what's wrong)
      - Is validation documented? (OpenAPI schemas, type hints)

      Where patterns are inconsistent, align with the dominant pattern. Prefer changes
      that affect fewer endpoints. Note any breaking changes that would require client
      updates—these may need versioning.

      **After completing your changes**, orchestrate verification:

      1. Spawn a sub-agent to review your work. Give it:
         - This task (API consistency)
         - The files you modified
         - Instruction to check: do changes break existing contracts unintentionally?
           Are response shapes valid? Is validation logic correct?

      2. Spawn a filter sub-agent. Give it the verification feedback and ask:
         which concerns are genuine breakages vs opinions about API design?

      3. Address filtered feedback, then commit.

  - name: propagation
    prompt: |
      API changes must propagate—but only where necessary.

      Check `git status` and `git diff` to see what API changes were made in this
      cycle. Note the specific endpoints and what changed about each (renamed fields,
      new parameters, changed response shapes).

      Three areas may need updates:

      1. **Internal callers**: Only code that directly calls the changed endpoints
      2. **Documentation**: Only docs that reference the changed endpoints
      3. **Tests**: Only tests that exercise the changed endpoints

      Launch three sub-agents **in parallel**—these areas are independent and can be
      updated simultaneously. Give each:
      - The list of changed endpoints
      - What specifically changed about each
      - Instruction to update only what's directly affected—no broader improvements

      Each sub-agent should make minimal necessary changes. If an area has nothing
      to update, that's fine.

      After all updates, run the full test suite. The measure of success is passing tests.

      **After sub-agents complete**, orchestrate verification:

      1. Spawn a sub-agent to review the combined changes. Check: are all callers
         updated? Are tests passing? Any missed propagation points?

      2. Spawn a filter sub-agent. Identify which concerns are genuine vs over-cautious.

      3. Address filtered feedback, then commit.
