name: error-handling
description: Establish consistent error handling patterns with self-orchestrated verification

prompt_prefix: |
  FIRST: Find and read all markdown documentation in this project before doing anything else.
  Search for and read: README files (root and subdirectories), CLAUDE.md, AGENTS.md, and all
  files in docs/ or documentation/ directories. Understand the codebase's patterns, conventions,
  and architecture. Only then proceed with your task. Sub-agents you spawn must do the same.

prompt_suffix: |
  Do not use the "question" tool or any tool requiring user input.
  Stage and commit your changes at the end with a descriptive message.

modes:
  - name: patterns
    prompt: |
      Survey and improve error handling patterns in this codebase.

      Before changing anything, understand what exists. Survey for:
      - What exception types are raised? (built-in, custom, library-specific)
      - How are errors caught? (bare except, specific types, exception groups)
      - Where do errors originate vs where are they handled?

      Identify where similar operations handle errors differently:
      - File operations that sometimes raise, sometimes return None
      - Network calls with varying timeout/retry behavior
      - Validation that uses exceptions in some places, return values in others

      For inconsistencies, choose the pattern that fits best and apply it uniformly.
      Prefer the pattern already used more often in the codebase.

      Keep exception types semantic: ValueError for bad inputs, RuntimeError for
      impossible states, custom types for domain-specific errors.

      Review error messages throughout:
      - Do they say what went wrong? ("Connection failed" vs "Error occurred")
      - Do they include relevant context? (which file, what value, what was expected)
      - For user-facing errors, do they suggest what to do next?

      Improve messages that are vague or unhelpful. Add context where it would help
      debugging. Avoid exposing internal implementation details in user-facing messages.

      **After completing your changes**, orchestrate verification:

      1. Spawn a sub-agent to review your work. Give it:
         - This task (error handling improvement)
         - The files you modified
         - Instruction to check: is error handling logic correct? No silent exception
           swallowing? Messages helpful and grammatically correct?

      2. Spawn a filter sub-agent. Give it the verification feedback and ask:
         which concerns are genuine vs opinions about exception hierarchy?

      3. Address filtered feedback, then commit.

  - name: propagation
    prompt: |
      Error handling changes affect code that catches or tests for specific exceptions.

      Check `git status` and `git diff` to see what error handling changed in this
      cycle. Note specifically:
      - Which exception types changed (ValueError -> CustomError)
      - Which messages changed that tests might assert on
      - Which patterns changed (return None -> raise, or vice versa)

      Three areas may need updates:
      1. **Catch blocks** expecting the old exception type
      2. **Tests** asserting on specific exceptions or messages
      3. **Documentation** describing error behavior

      Launch three sub-agents **in parallel**—these areas are independent and can be
      updated simultaneously. Give each:
      - The specific changes (from git status/diff)
      - Instruction to update only code directly affected by those changes—no
        additional improvements

      If an area has nothing to update, that's fine. Minimal changes are better
      than thorough ones.

      After all updates, run tests. Failing tests indicate missed sync points.

      **After sub-agents complete**, orchestrate verification:

      1. Spawn a sub-agent to review the combined changes. Check: are all catch
         blocks updated? Are tests passing? Any missed propagation points?

      2. Spawn a filter sub-agent. Identify which concerns are genuine vs over-cautious.

      3. Address filtered feedback, then commit.
